{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Statistical Data Analysis: Machine Learning Assignment\n",
    "\n",
    "# SOLUTIONS\n",
    "\n",
    "- Statistical Data Analysis (SPA6328)\n",
    "- Academic Year: 2020-2021\n",
    "- Module Organiser: Dr Seth Zenz\n",
    "- Module Associate: Prof Adrian Bevan\n",
    "\n",
    "Copyright (C) Queen Mary University of London\n",
    "\n",
    "## This assessment is for summative feedback.\n",
    "\n",
    "In this assignment you will analyse the iris data using decision tree based classifiers.  Specifically we are using the AdaBoost decision tree.  Each decision tree by itself is considered a weak learner, and the AdaBoost computes an output based on a collection of trees. This weighted averaging process leads to a more robust machine learning algorithm (i.e. one that is more robust in that its outputs on new unseen data samples should be similar to that used for testing and training, and that overtraining issues are reduced).  The process also results in what is called a strong learner - one that has a stronger separation between different categories of event than would be the case with a single tree, or indeed the individual features that are input into that tree.\n",
    "\n",
    "By now you should be very familiar with the iris data, both in terms of the 1D and 2D information, and what you can learn from the 1D distributions in terms of the ability to separate the three different types of iris from each other.  Here we take the next step to use a machine learning algorithm to simultaneously benefit from the 4-dimensional feature space to separate signal from background.\n",
    "\n",
    "## Task\n",
    "\n",
    "Train a classifier using the iris data and study the performance characteristics of this classifier in detail by working through this notebook.\n",
    "You should:\n",
    "- Work through the Iris data decision tree classification example in order to answer the following questions\n",
    "  - Using a train split of 0.5. Explore the effect of (a) changing the number of estimators, and (b) changing the tree depth, on the performance of the classifier. For this exercise tabulate results for including 10, 100, 500 and 1000 estimators (i.e. boosting iterations) and for tree depths of 1, 2, 3.  Measure performance by the fraction of mis-classified test examples.\n",
    "  - Repeat the above using a train split of 0.8.\n",
    "  - What is the configuration that leads to the least number of mis-classified examples.\n",
    "  - Why do you think, in detail, that any residual example(s) are mis-classified by the algorithm. If there are no-mis-classified examples, then does that concern you with regard to the use of this algorithm and the sample sizes used for train and test. You may wish to reflect on the earlier formative assignments and the notes to guide your response to this question.\n",
    "  - Reflect on the results you obtained for the train split size. Remark on any differences in performance that you observe.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mLoad the sklearn Iris data\u001b[0m\n",
      "\n",
      "Iris data have been split into test and train samples\n",
      "\tN(train)             =  120\n",
      "\tN(test)              =  30\n",
      "\tTrain split          =  0.8\n",
      "\tnumber_of_estimators =  10\n",
      "\ttree_depth           =  3\n",
      "\tmin_leaf_size        =  1\n",
      "\u001b[1mFit the decision tree\u001b[0m\n",
      "... now compute the decision tree score\n",
      "\n",
      "Decision Tree Classifier Score is:\n",
      "\tTrain Score =  1.0  (This measure of performance is biased)\n",
      "\tTest Score  = 1.0000\n",
      "\tNumber of mis-classified test data = 0.0, fraction of mis-classified examples = 0.000\n",
      "\n",
      "\u001b[1mStudy the test data\u001b[0m\n",
      "\n",
      "confusion matrix (test) = \n",
      " [[11  0  0]\n",
      " [ 0 13  0]\n",
      " [ 0  0  6]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 864x504 with 2 Axes>"
      ]
     },
     "execution_count": 23,
     "metadata": {
      "image/png": {
       "height": 411,
       "width": 638
      },
      "needs_background": "light"
     },
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Truth\tPrediction\tP(type = 1)\tP(type = 2)\tP(type = 3)\tCorrect Prediction\n",
      "2\t2\t0.0000\t0.0000\t1.0000\tTrue\n",
      "1\t1\t0.0000\t1.0000\t0.0000\tTrue\n",
      "0\t0\t1.0000\t0.0000\t0.0000\tTrue\n",
      "2\t2\t0.0000\t0.0000\t1.0000\tTrue\n",
      "0\t0\t1.0000\t0.0000\t0.0000\tTrue\n",
      "2\t2\t0.0000\t0.0000\t1.0000\tTrue\n",
      "0\t0\t1.0000\t0.0000\t0.0000\tTrue\n",
      "1\t1\t0.0000\t1.0000\t0.0000\tTrue\n",
      "1\t1\t0.0000\t1.0000\t0.0000\tTrue\n",
      "1\t1\t0.0000\t1.0000\t0.0000\tTrue\n",
      "2\t2\t0.0000\t0.0000\t1.0000\tTrue\n",
      "1\t1\t0.0000\t1.0000\t0.0000\tTrue\n",
      "1\t1\t0.0000\t1.0000\t0.0000\tTrue\n",
      "1\t1\t0.0000\t1.0000\t0.0000\tTrue\n",
      "1\t1\t0.0000\t1.0000\t0.0000\tTrue\n",
      "0\t0\t1.0000\t0.0000\t0.0000\tTrue\n",
      "1\t1\t0.0000\t1.0000\t0.0000\tTrue\n",
      "1\t1\t0.0000\t1.0000\t0.0000\tTrue\n",
      "0\t0\t1.0000\t0.0000\t0.0000\tTrue\n",
      "0\t0\t1.0000\t0.0000\t0.0000\tTrue\n",
      "2\t2\t0.0000\t0.0000\t1.0000\tTrue\n",
      "1\t1\t0.0000\t1.0000\t0.0000\tTrue\n",
      "0\t0\t1.0000\t0.0000\t0.0000\tTrue\n",
      "0\t0\t1.0000\t0.0000\t0.0000\tTrue\n",
      "2\t2\t0.0000\t0.0000\t1.0000\tTrue\n",
      "0\t0\t1.0000\t0.0000\t0.0000\tTrue\n",
      "0\t0\t1.0000\t0.0000\t0.0000\tTrue\n",
      "1\t1\t0.0000\t1.0000\t0.0000\tTrue\n",
      "1\t1\t0.0000\t1.0000\t0.0000\tTrue\n",
      "0\t0\t1.0000\t0.0000\t0.0000\tTrue\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import load_iris\n",
    "#\n",
    "# If having studied the iris data you wish to (not assessed) explore a larger data set, then the \n",
    "# NIST handwriting data (numbers 0, 1, 2, ... 9) can be loaded using load_digits. To use this one\n",
    "# needs to change n_classes to 10.\n",
    "#\n",
    "# Uncomment the following line to import the load_digits function\n",
    "#\n",
    "#from sklearn.datasets import load_digits\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "# Parameters\n",
    "n_classes = 3\n",
    "plot_colors = \"ryb\"\n",
    "train_split_size = 0.8     # the fraction of examples used for training\n",
    "number_of_estimators = 10 # the number of boosting iterations\n",
    "tree_depth    = 3          # number of divisions of data\n",
    "min_leaf_size = 1          # minimum number of examples in a leaf\n",
    "\n",
    "# Load data\n",
    "print(\"\\033[1mLoad the sklearn Iris data\\033[0m\\n\")\n",
    "iris = load_iris()\n",
    "\n",
    "# split the data into test and train samples. The train sample will be used to learn\n",
    "# the model, and the test sample will be used to evaluate module performance.\n",
    "X_train, X_test, y_train, y_test = train_test_split(iris.data, iris.target, random_state=0, train_size=train_split_size)\n",
    "print(\"Iris data have been split into test and train samples\")\n",
    "print(\"\\tN(train)             = \", len(X_train))\n",
    "print(\"\\tN(test)              = \", len(X_test))\n",
    "print(\"\\tTrain split          = \", train_split_size)\n",
    "print(\"\\tnumber_of_estimators = \", number_of_estimators)\n",
    "print(\"\\ttree_depth           = \", tree_depth)\n",
    "print(\"\\tmin_leaf_size        = \", min_leaf_size)\n",
    "\n",
    "\n",
    "print(\"\\033[1mFit the decision tree\\033[0m\")\n",
    "DT_clf  = DecisionTreeClassifier(max_depth=tree_depth, min_samples_leaf=min_leaf_size)\n",
    "BDT_clf = AdaBoostClassifier(base_estimator=DT_clf, n_estimators=number_of_estimators).fit(X_train, y_train)\n",
    "\n",
    "print(\"... now compute the decision tree score\")\n",
    "train_score = BDT_clf.score(X_train, y_train)\n",
    "test_score  = BDT_clf.score(X_test, y_test)\n",
    "\n",
    "print(\"\\nDecision Tree Classifier Score is:\")\n",
    "print(\"\\tTrain Score = \", train_score, \" (This measure of performance is biased)\")\n",
    "print(\"\\tTest Score  = {:5.4f}\".format(test_score))\n",
    "n_misclassified = (1-test_score)*len(X_test)\n",
    "print(\"\\tNumber of mis-classified test data = {:2.1f}, fraction of mis-classified examples = {:4.3f}\".format(n_misclassified, 1-test_score ))\n",
    "\n",
    "\n",
    "#\n",
    "# Use the test data to compute a confusion matrix and to compare predictions against\n",
    "# the ground truth labels.\n",
    "#\n",
    "print(\"\\n\\033[1mStudy the test data\\033[0m\")\n",
    "predictions = BDT_clf.predict(X_test)\n",
    "prob_predictions = BDT_clf.predict_proba(X_test)\n",
    "BDTcm = confusion_matrix(y_test, predictions)\n",
    "print(\"\\nconfusion matrix (test) = \\n\", BDTcm)\n",
    "sns.heatmap(BDTcm, center=True)\n",
    "plt.show()\n",
    "\n",
    "#\n",
    "# Compare the ground truth and model prediction\n",
    "#\n",
    "print(\"Truth\\tPrediction\\tP(type = 1)\\tP(type = 2)\\tP(type = 3)\\tCorrect Prediction\")\n",
    "for i in range(len(predictions)):\n",
    "    Match = False\n",
    "    if predictions[i] == y_test[i]:\n",
    "        Match = True\n",
    "    print(\"{:}\\t{:}\\t{:5.4f}\\t{:5.4f}\\t{:5.4f}\\t{:}\".format(y_test[i], predictions[i], prob_predictions[i][0], prob_predictions[i][1], prob_predictions[i][2], Match))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "---------------------------\n",
    "## Solution\n",
    "\n",
    "Table exploring the effect of (a) changing the number of estimators, and (b) changing the tree depth, on the performance of the classifer. For this exercise tabulate results for including 10, 100, 500 and 1000 estimators (i.e. boosting iterations) and for tree depths of 1, 2, 3.  Measure performance by the fraction of mis-classified test examples.\n",
    "\n",
    "\n",
    "----------------\n",
    "Test split = 0.5\n",
    "| Tree Depth  | 10 iter  | 100 iter  | 500 iter  | 1000 iter |\n",
    "| ----------- | -------- | --------- | --------- | --------- |\n",
    "| 1           | 0.080    | 0.080     | 0.080     | 0.080     |\n",
    "| 2           | 0.040    | 0.040     | 0.133     | 0.040     |\n",
    "| 3           | 0.040    | 0.040     | 0.040     | 0.040     |\n",
    "\n",
    "----------------\n",
    "Test split = 0.8\n",
    "| Tree Depth  | 10 iter  | 100 iter  | 500 iter  | 1000 iter |\n",
    "| ----------- | -------- | --------- | --------- | --------- |\n",
    "| 1           | 0.033    | 0.100     | 0.100     | 0.100     |\n",
    "| 2           | 0.000    | 0.033     | 0.000     | 0.000     |\n",
    "| 3           | 0.000    | 0.033     | 0.033     | 0.033     |\n",
    "\n",
    "\n",
    "From the results obtained State the least number of mis-classified examples:\n",
    "\n",
    "   **min(N-misclassified) = 0**\n",
    "\n",
    "Reflect on this outcome\n",
    "\n",
    "   **With a train split of 0.5 there are 75 training examples, with a 0.8 fraction there are 120 training examples. These are small numbers of data.  It is possible to perfectly classify the data using the decision tree approach with these limited samples, however this algorithm has a potential for overtraining to occur.  The perfect classification could be related to having overtrained the trees.  To test that one would want to do further study, and/or have a larger data sample.**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (Ubuntu Linux)",
   "language": "python",
   "name": "python3-ubuntu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}